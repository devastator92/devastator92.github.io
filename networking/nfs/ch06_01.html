<html>
<!-- Mirrored from nnc3.com/mags/Networking2/nfs/ch06_01.htm by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 28 Jul 2017 17:53:37 GMT -->
<head><title>System Administration Using the Network File System (Managing NFS and NIS, 2nd Edition)</title><link rel="stylesheet" type="text/css" href="../style/style1.css" />

<meta name="DC.Creator" content="Hal Stern, Mike Eisler and Ricardo Labiaga" /><meta name="DC.Format" content="text/xml" scheme="MIME" /><meta name="DC.Language" content="en-US" /><meta name="DC.Publisher" content="O'Reilly &amp; Associates, Inc." /><meta name="DC.Source" scheme="ISBN" content="1565925106L" /><meta name="DC.Subject.Keyword" content="stuff" /><meta name="DC.Title" content="Managing NFS and NIS, 2nd Edition" /><meta name="DC.Type" content="Text.Monograph" />

</head><body bgcolor="#ffffff">

<img alt="Book Home" border="0" src="gifs/smbanner.gif" usemap="#banner-map" /><map name="banner-map"><area shape="rect" coords="1,-2,616,66" href="index.html" alt="Managing NFS &amp; NIS" /><area shape="rect" coords="629,-11,726,25" href="jobjects/fsearch.html" alt="Search this book" /></map>

<div class="navbar"><table width="684" border="0"><tr><td align="left" valign="top" width="228"><a href="ch05_06.html"><img alt="Previous" border="0" src="../gifs/txtpreva.gif" /></a></td><td align="center" valign="top" width="228"><a href="index.html"></a></td><td align="right" valign="top" width="228"><a href="ch06_02.html"><img alt="Next" border="0" src="../gifs/txtnexta.gif" /></a></td></tr></table><div>




<h1 class="chapter">Chapter 6. System Administration Using the Network File System</h1>
<div class="htmltoc"><h4 class="tochead">Contents:</h4>
      <a href="#nfs2-CHP-6-SECT-1">Setting up NFS</a><br />
<a href="ch06_02.html">Exporting filesystems</a><br />
<a href="ch06_03.html">Mounting filesystems</a><br />
<a href="ch06_04.html">Symbolic links</a><br />
<a href="ch06_05.html">Replication</a><br />
<a href="ch06_06.html">Naming schemes</a><br /></p><p></div>

The Network File System (NFS) is a distributed<a name="INDEX-806" /></a> <a name="INDEX-807" /></a>
filesystem that provides transparent access to remote disks. Just as
NIS allows you to centralize administration of user and host
information, NFS allows you to centralize administration of disks.
Instead of duplicating common directories such as
<em class="emphasis">/usr/local</em> on every system, NFS provides a
single copy of the directory that is shared by all systems on the
network. To a host running NFS, remote filesystems are
indistinguishable from
<a name="INDEX-808" /></a>
<a name="INDEX-809" /></a>local ones. For the user, NFS
means that he or she doesn't have to log into other systems to
access files. There is no need to use <em class="emphasis">rcp</em> or
tapes to move files onto the local system. Once NFS has been set up
properly, users should be able to do all their work on their local
system; remote files (data and executables) will appear to be local
to their own system. NFS and NIS are frequently used together: NIS
makes sure that configuration information is propagated to all hosts,
and NFS ensures that the files a user needs are accessible from these
hosts.
</p><p>

NFS is also built on the RPC protocol and
<a name="INDEX-810" /></a>
<a name="INDEX-811" /></a>imposes a client-server relationship on
the hosts that use it. An NFS server is a host that owns one or more
filesystems and makes them available on the network; NFS clients
mount filesystems from one or more servers. This follows the normal
client-server model where the server owns a resource that is used by
the client. In the case of NFS, the resource is a physical disk drive
that is shared by all clients of the server.
</p><p>

There are two aspects to system administration using NFS: choosing a
filesystem naming and mounting scheme, and
<a name="INDEX-812" /></a>
<a name="INDEX-813" /></a>
<a name="INDEX-814" /></a>
<a name="INDEX-815" /></a>
<a name="INDEX-816" /></a>
<a name="INDEX-817" /></a>then
configuring the servers and clients to adhere to this scheme. The
goal of any naming scheme should be to use network transparency
wisely. Being able to mount filesystems from any server is useful
only if the files are presented in a manner that is consistent with
the users' expectations.
</p><p>

If NFS has been set up correctly, it should be transparent to the
user. For example, if locally developed applications were found in
<em class="emphasis">/usr/local/bin</em> before NFS was installed, they
should continue to be found there when NFS is running, whether
<em class="emphasis">/usr/local/bin</em> is on a local filesystem or a
remote one. To the user, the actual disk holding
<em class="emphasis">/usr/local/bin</em> isn't important as long as
the executables are accessible and built for the right machine
architecture. If users must change their environments to locate files
accessed through NFS, they will probably dislike the new network
architecture because it changes the way things work.
</p><p>

An environment with many NFS servers
<a name="INDEX-818" /></a>and hundreds of clients can quickly
become overwhelming in terms of management complexity. Successful
system administration of a large NFS network requires adding some
intelligence to the standard procedures. The cost of consistency on
the network should not be a large administrative overhead. One tool
that greatly eases the task of running an NFS network
<a name="INDEX-819" /></a>is the
<em class="emphasis">automounter</em>, which applies NIS management to NFS
configuration. This chapter starts with a quick look at how to get
NFS up and running on clients and servers, and then explores NFS
naming schemes and common filesystem planning problems. We'll
cover the automounter in detail in <a href="ch09_01.html">Chapter 9, "The Automounter"</a>.
</p><p>

<div class="sect1"><a name="nfs2-CHP-6-SECT-1" /></a>
<h2 class="sect1">6.1. Setting up NFS</h2>

Setting up NFS on clients and servers involves <a name="INDEX-820" /></a>
<a name="INDEX-821" /></a>starting
the daemons that handle the NFS RPC protocol, starting additional
daemons for auxiliary services such as file locking, and then simply
exporting filesystems from the NFS servers and mounting them on the
clients.
</p><p>

On an NFS client, you need to<a name="INDEX-822" /></a> <a name="INDEX-823" /></a>
<a name="INDEX-824" /></a>
<a name="INDEX-825" /></a>
<a name="INDEX-826" /></a>
<a name="INDEX-827" /></a> have the <em class="emphasis">lockd</em>
and <em class="emphasis">statd</em> daemons running in order to use NFS.
These daemons are generally started<a name="INDEX-828" /></a> in a boot script (Solaris uses
/<em class="emphasis">etc/init.d/nfs.client</em>):
</p><p>

<blockquote><pre class="code">if [ -x /usr/lib/nfs/statd -a -x /usr/lib/nfs/lockd ]
then
	/usr/lib/nfs/statd &gt; /dev/console 2&gt;&amp;1
	/usr/lib/nfs/lockd &gt; /dev/console 2&gt;&amp;1
fi</pre></blockquote>

On some non-Solaris systems, there may<a name="INDEX-829" /></a>
<a name="INDEX-830" /></a><a name="INDEX-831" /></a>
<a name="INDEX-832" /></a> also be <em class="emphasis">biod</em>
daemons that get started. The <em class="emphasis">biod</em> daemons
perform block I/O operations for NFS clients, performing some simple
read-ahead and write-behind performance optimizations. You run
multiple instances of <em class="emphasis">biod</em> so that each client
process can have multiple NFS requests outstanding at any time. Check
your vendor's documentation for the proper invocation of the
<em class="emphasis">biod</em> daemons. Solaris does not have
<em class="emphasis">biod</em> daemons because the read-ahead and
write-behind function is handled by a tunable number of asynchronous
I/O threads that reside in the system kernel.
</p><p>

The <em class="emphasis">lockd</em> and <em class="emphasis">statd</em> daemons
handle file locking and lock recovery on the client. These locking
daemons also run on an NFS server, and the client-side daemons
coordinate file locking on the NFS server through their server-side
counterparts. We'll come back to file locking later when we
discuss how NFS handles state information.
</p><p>

On an NFS server, NFS services are started with the
<em class="emphasis">nfsd</em> and <em class="emphasis">mountd</em> daemons, as
well as the file locking daemons used on the client. You should see
the NFS server daemons started in a boot script (Solaris uses
<em class="emphasis">/etc/init.d/nfs.server</em>):
</p><p>

<blockquote><pre class="code">if grep -s nfs /etc/dfs/sharetab &gt;/dev/null ; then
	/usr/lib/nfs/mountd
	/usr/lib/nfs/nfsd -a 16
fi</pre></blockquote>

On most NFS servers, there is a file that contains the list of
filesystems the server will allow clients to mount via NFS. Many
servers store this<a name="INDEX-833" /></a> list in
<em class="emphasis">/etc/exports</em> file. Solaris stores the list in
<b class="emphasis-bold">/</b><em class="emphasis">etc/dfs/dfstab</em>. In the
previous script file excerpt, the NFS server daemons are not started
unless the host shares (exports) NFS filesystems in the
<em class="emphasis">/etc/dfs/dfstab</em> file. (The reference to
<em class="emphasis">/etc/dfs/sharetab</em> in the script excerpt is not a
misprint; see <a href="ch06_02.html#nfs2-CHP-6-SECT-2">Section 6.2, "Exporting filesystems"</a>.) If there are filesystems to be made
available for NFS service, the machine initializes the export list
and starts the NFS daemons. As with the client-side, check your
vendor's documentation or the boot scripts themselves for
details on how the various server daemons are started.
</p><p>

The <em class="emphasis">nfsd</em> daemon accepts NFS RPC requests
<a name="INDEX-834" /></a>
<a name="INDEX-835" /></a>and
executes them on the server. Some servers run multiple copies of the
daemon so that they can handle several RPC requests at once. In
Solaris, a single copy of the daemon is run, but multiple threads run
in the kernel to provide parallel NFS service. Varying the number of
daemons or threads on a server is a performance tuning issue that we
will discuss in <a href="ch17_01.html">Chapter 17, "Network Performance Analysis"</a>. By default,
<em class="emphasis">nfsd</em> listens over both the TCP and UDP transport
protocols. There are several options to modify this behavior and also
to tune the TCP connection management. These options will be
discussed in <a href="ch17_01.html">Chapter 17, "Network Performance Analysis"</a> as well.
</p><p>

The <em class="emphasis">mountd</em> daemon handles client mount
<a name="INDEX-836" /></a>
<a name="INDEX-837" /></a>requests.
The mount protocol <a name="INDEX-838" /></a>
<a name="INDEX-839" /></a>is
not part of NFS. The mount protocol is used by an NFS server to tell
a client what filesystems are available (exported) for mounting. The
NFS client uses the mount protocol to get a filehandle for the
exported<a name="INDEX-840" /></a>
<a name="INDEX-841" /></a>
filehandle.
</p><p>

</div>












<hr width="684" align="left" />
<div class="navbar"><table width="684" border="0"><tr><td align="left" valign="top" width="228"><a href="ch05_06.html"><img alt="Previous" border="0" src="../gifs/txtpreva.gif" /></a></td><td align="center" valign="top" width="228"><a href="index.html"><img alt="Home" border="0" src="../gifs/txthome.gif" /></a></td><td align="right" valign="top" width="228"><a href="ch06_02.html"><img alt="Next" border="0" src="../gifs/txtnexta.gif" /></a></td></tr><tr><td align="left" valign="top" width="228">5.6. What next?</td><td align="center" valign="top" width="228"><a href="index/index.html"><img alt="Book Index" border="0" src="../gifs/index.gif" /></a></td><td align="right" valign="top" width="228">6.2. Exporting filesystems</td></tr></table><div>
<hr width="684" align="left" />

<img alt="Library Navigation Links" border="0" src="../gifs/navbar.gif" usemap="#library-map" />
<p><font size="-1"><a href="copyrght.html">Copyright &copy; 2002</a> O'Reilly &amp; Associates. All rights reserved.</font></p>

<map name="library-map"><area shape="rect" coords="1,0,84,90" href="../index.html" /><area shape="rect" coords="86,-7,176,90" href="../ssh/index.html" /><area shape="rect" coords="178,0,265,101" href="../tcp/index.html" /><area shape="rect" coords="266,0,333,90" href="index.html" /><area shape="rect" coords="334,-1,429,93" href="../snmp/index.html" /><area shape="rect" coords="431,0,529,116" href="../tshoot/index.html" /><area shape="rect" coords="534,0,594,104" href="../dns/index.html" /><area shape="rect" coords="595,1,704,108" href="../fire/index-2.html" /></map>

</div></div></div></div></body>
<!-- Mirrored from nnc3.com/mags/Networking2/nfs/ch06_01.htm by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 28 Jul 2017 17:53:39 GMT -->
</html>